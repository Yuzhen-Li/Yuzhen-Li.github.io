<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>恩泽の博客</title>
  <icon>https://www.gravatar.com/avatar/366ef683e1866ae1c05b20ceb4ff7fd9</icon>
  <subtitle>有信、有望、有爱。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://yuzhen-li.github.io/"/>
  <updated>2018-04-16T08:00:39.363Z</updated>
  <id>https://yuzhen-li.github.io/</id>
  
  <author>
    <name>李恩泽(Enze_Li)</name>
    <email>liyuzhen@cmbchina.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>NLP处理之polyglot</title>
    <link href="https://yuzhen-li.github.io/2018/04/15/NLP%E5%A4%84%E7%90%86%E4%B9%8Bpolyglot/"/>
    <id>https://yuzhen-li.github.io/2018/04/15/NLP处理之polyglot/</id>
    <published>2018-04-15T15:23:12.000Z</published>
    <updated>2018-04-16T08:00:39.363Z</updated>
    
    <content type="html"><![CDATA[<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1> <figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">$ pip install polyglot</span><br><span class="line"> ``` </span><br><span class="line"></span><br><span class="line">安装依赖库</span><br><span class="line"></span><br><span class="line"> ``` </span><br><span class="line">$ sudo apt-get install python-numpy libicu-dev</span><br><span class="line"> ``` </span><br><span class="line"></span><br><span class="line">在Python中<span class="keyword">import</span> _icu（这个语句其实在polyglot安装成功后<span class="keyword">import</span> polyglot.text是报错发现的）的时候，发现importerror …. _icu.so: no defined …(忘了)</span><br><span class="line">所以我们这个动态链接库是没有build成功的。 </span><br><span class="line">可能是pip install的时候没有生成一个好的_icu.so</span><br><span class="line">所以我们要在安装python模块的时候入手，icu4c模块应该没问题了。</span><br><span class="line">编译安装成功</span><br><span class="line">我就不用pip安装了，直接下源码</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">``` </span><br><span class="line">wget https:<span class="comment">//pypi.python.org/packages/bf/1f/cea237f542e3bb592980008a734850e8cbbc25c19c72c98767c71c1bd9c2/PyICU-2.0.3.tar.gz</span></span><br><span class="line"># (去官网下载，我的是<span class="number">1.9</span><span class="number">.3</span>)</span><br><span class="line"></span><br><span class="line">tar zxvf PyICU<span class="number">-2.0</span><span class="number">.3</span>.tar.gz</span><br><span class="line">cd PyICU<span class="number">-2.0</span><span class="number">.3</span>.tar.gz</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">此时如果你是linux系统要修改一下setup.py文件</span><br><span class="line">具体如下图所示</span><br><span class="line"></span><br><span class="line">![图<span class="number">1</span>](/assets/blogImg/test1.jpg)</span><br><span class="line">![图<span class="number">2</span>](/assets/blogImg/test2.jpg)</span><br><span class="line"></span><br><span class="line">然后</span><br></pre></td></tr></table></figure><p>python setup.py build<br>sudo python setup.py install</p><pre><code># 分词</code></pre><p>from polyglot.text import Text</p><p>blob = u”””The baby eagle liked the nest. It was the only world he had ever known. It was warm and comfortable, had a great view, and even better, he had all the food and love and attention that a great mother eagle could provide”””</p><p>text = Text(blob)</p><p>text.words</p><pre><code># 词性标注首先需要下载通用词性标签集</code></pre><p>polyglot download embeddings2.en pos2.en</p><pre><code>这一步要等好久好久，反正我等得是花都谢了，N次怀疑电脑卡死了。词性标注具体代码如下：</code></pre><p>from polyglot.text import Text</p><p>blob = “””We will meet at eight o’clock on Thursday morning.”””<br>text = Text(blob)</p><p>text.pos_tags</p><pre><code># 实体识别首先也要安装相关依赖包</code></pre><p>polyglot download embeddings2.en ner2.en</p><pre><code>相关代码如下：</code></pre><p>from polyglot.text import Text<br>blob = “””The Israeli Prime Minister Benjamin Netanyahu has warned that Iran poses a “threat to the entire world”.”””<br>text = Text(blob)</p><p>text.entities</p><pre><code>但是上面打印出来的结果不是字典的形式，为了最后成为字典，可以这样处理</code></pre><p>nerL = [ ]<br>nerR = { }<br>for sent int text.sentences:<br>    for entity in sent.entities:<br>        nerL.append(entity)</p><p>for iter in nerL:<br>    for i in iter:<br>        nerR[i] = iter.tag</p><p>print(R)<br><code>`</code> </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h1&gt; &lt;figure class=&quot;highlight clean&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span
      
    
    </summary>
    
      <category term="技术博客" scheme="https://yuzhen-li.github.io/categories/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="自然语言处理(NLP)" scheme="https://yuzhen-li.github.io/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-NLP/"/>
    
      <category term="polyglot" scheme="https://yuzhen-li.github.io/tags/polyglot/"/>
    
  </entry>
  
  <entry>
    <title>NLP的JSON格式输出</title>
    <link href="https://yuzhen-li.github.io/2018/04/15/NLP%E7%9A%84JSON%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA/"/>
    <id>https://yuzhen-li.github.io/2018/04/15/NLP的JSON格式输出/</id>
    <published>2018-04-15T15:23:12.000Z</published>
    <updated>2018-04-16T07:46:30.247Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分词的JSON格式输出"><a href="#分词的JSON格式输出" class="headerlink" title="分词的JSON格式输出"></a>分词的JSON格式输出</h1><h2 id="实现核心"><a href="#实现核心" class="headerlink" title="实现核心"></a>实现核心</h2><p>实现的核心是构造 convertToJson(words)函数，首先需要将各种策略下的分词输出，转化成list输出。保证输入该函数的参数是list。该函数的具体代码如下：</p><pre><code class="Python"><span class="function"><span class="keyword">def</span> <span class="title">convertToJson</span><span class="params">(words)</span>:</span>    <span class="comment">#the paramter words have been already segmented</span>    <span class="comment">#词性标注功能</span>    postagger = Postagger()      postagger.load(<span class="string">"/models/pyltp/ltp_data_v3.4.0/pos.model"</span>)      postags = postagger.postag(words)     postagger.release()  <span class="comment"># 释放模型 </span>    <span class="comment"># 结果整合为json。这是重点。我把原代码的print全部注释。  </span>    resultJson=[] <span class="comment">#创建一个空列表，用于保存json数据。  </span>    length = len(words)    begin= []    end = []    begin.append(<span class="number">0</span>)    i = <span class="number">0</span>    <span class="keyword">while</span> i &lt; length:         end.append(begin[i] + len(words[i]) - <span class="number">1</span>)         <span class="keyword">if</span> i == length - <span class="number">1</span>:             <span class="keyword">break</span>         <span class="keyword">else</span>:             begin.append(begin[i] + len(words[i]))         i=i+<span class="number">1</span>    <span class="keyword">for</span> index <span class="keyword">in</span> range(len(words)):<span class="comment">#遍历结果  </span>        resultJson.append({<span class="string">'id'</span>:index,<span class="string">'begin'</span>:begin[index],<span class="string">'end'</span>:end[index],<span class="string">'cont'</span>:words[index],<span class="string">'pos'</span>:postags[index]}) <span class="comment">#将各功能的结果对应地添加到json中  </span>    <span class="keyword">return</span> resultJson <span class="comment"># 返回函数结果  </span></code></pre><p>这个函数中用pyltp库实现了词性标注，而且标注了每个分词在原来句子中的位置。<br>最后通过一个大循环把所有的结果存到resultJson，最后可以应用dumps函数实现json格式转换。</p><pre><code>result=json.dumps({&apos;status&apos;:&apos;0&apos;,&apos;inputStr&apos;:inputStr,&apos;mode&apos;:methodNum,&apos;outputStr&apos;:finalResult},ensure_ascii=False,indent=2)</code></pre><h2 id="遇到的问题和解决方案"><a href="#遇到的问题和解决方案" class="headerlink" title="遇到的问题和解决方案"></a>遇到的问题和解决方案</h2><p>   在与前端联调的过程中出现问题，总是不同，有500的错误提出。消耗了我两天多的时间，最后发现问题是：前端发给我的数字都是字符串，而我在后面代码中的数字都是int型的，所以出问题。最后的解决办法是，将前端发过来的数字强制转换成int型。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;分词的JSON格式输出&quot;&gt;&lt;a href=&quot;#分词的JSON格式输出&quot; class=&quot;headerlink&quot; title=&quot;分词的JSON格式输出&quot;&gt;&lt;/a&gt;分词的JSON格式输出&lt;/h1&gt;&lt;h2 id=&quot;实现核心&quot;&gt;&lt;a href=&quot;#实现核心&quot; class=&quot;
      
    
    </summary>
    
      <category term="技术博客" scheme="https://yuzhen-li.github.io/categories/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="自然语言处理(NLP)" scheme="https://yuzhen-li.github.io/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-NLP/"/>
    
      <category term="分词" scheme="https://yuzhen-li.github.io/tags/%E5%88%86%E8%AF%8D/"/>
    
      <category term="JSON" scheme="https://yuzhen-li.github.io/tags/JSON/"/>
    
  </entry>
  
  <entry>
    <title>自然语言处理textblog安装使用</title>
    <link href="https://yuzhen-li.github.io/2018/04/15/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86textblog%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/"/>
    <id>https://yuzhen-li.github.io/2018/04/15/自然语言处理textblog安装使用/</id>
    <published>2018-04-15T15:23:12.000Z</published>
    <updated>2018-04-15T16:09:52.777Z</updated>
    
    <content type="html"><![CDATA[<h1 id="自然语言处理-textblog-安装使用"><a href="#自然语言处理-textblog-安装使用" class="headerlink" title="自然语言处理 textblog 安装使用"></a>自然语言处理 textblog 安装使用</h1><h2 id="TextBlob是什么？"><a href="#TextBlob是什么？" class="headerlink" title="TextBlob是什么？"></a>TextBlob是什么？</h2><p>TextBlob是一个用Python编写的开源的文本处理库。它可以用来执行很多自然语言处理的任务，比如，词性标注，名词性成分提取，情感分析，文本翻译，等等。你可以在官方文档阅读TextBlog的所有特性。</p><p>github 地址：<a href="https://github.com/sloria/TextBlob/" target="_blank" rel="noopener">https://github.com/sloria/TextBlob/</a></p><p>文档地址：<a href="https://textblob.readthedocs.io/en/dev/" target="_blank" rel="noopener">https://textblob.readthedocs.io/en/dev/</a><br>TextBlob是在NLTK和pattern基础上构建的，并且与这两者完美契合。</p><h2 id="安装-TextBlob"><a href="#安装-TextBlob" class="headerlink" title="安装 TextBlob"></a>安装 TextBlob</h2><pre><code>$ pip install -U textblob$ python -m textblob.download_corpora # 下载nltk数据包，如果已经在nltk 安装的时候下载好了nltk数据包，不需要此步骤</code></pre><h2 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h2><p>Create a TextBlob（创建一个textblob对象）</p><pre><code>from textblob import TextBlobwiki = TextBlob(&quot;Python is a high-level, general-purpose programming language.&quot;)</code></pre><p>Part-of-speech Tagging（词性标注）</p><pre><code>wiki.tags[(&apos;Python&apos;, &apos;NNP&apos;), (&apos;is&apos;, &apos;VBZ&apos;), (&apos;a&apos;, &apos;DT&apos;), (&apos;high-level&apos;, &apos;JJ&apos;), (&apos;general-purpose&apos;, &apos;JJ&apos;), (&apos;programming&apos;, &apos;NN&apos;), (&apos;language&apos;, &apos;NN&apos;)]</code></pre><p>Sentiment Analysis（情感分析）</p><pre><code>testimonial = TextBlob(&quot;Textblob is amazingly simple to use. What great fun!&quot;)testimonial.sentimentSentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)testimonial.sentiment.polarity0.39166666666666666</code></pre><p>Tokenization（分词和分句）</p><pre><code>zen = TextBlob(&quot;Beautiful is better than ugly. &quot;...                &quot;Explicit is better than implicit. &quot;...                &quot;Simple is better than complex.&quot;)zen.wordsWordList([&apos;Beautiful&apos;, &apos;is&apos;, &apos;better&apos;, &apos;than&apos;, &apos;ugly&apos;, &apos;Explicit&apos;, &apos;is&apos;, &apos;better&apos;, &apos;than&apos;, &apos;implicit&apos;, &apos;Simple&apos;, &apos;is&apos;, &apos;better&apos;, &apos;than&apos;, &apos;complex&apos;])zen.sentences[Sentence(&quot;Beautiful is better than ugly.&quot;), Sentence(&quot;Explicit is better than implicit.&quot;), Sentence(&quot;Simple is better than complex.&quot;)]</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;自然语言处理-textblog-安装使用&quot;&gt;&lt;a href=&quot;#自然语言处理-textblog-安装使用&quot; class=&quot;headerlink&quot; title=&quot;自然语言处理 textblog 安装使用&quot;&gt;&lt;/a&gt;自然语言处理 textblog 安装使用&lt;/h1&gt;&lt;
      
    
    </summary>
    
      <category term="技术博客" scheme="https://yuzhen-li.github.io/categories/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="自然语言处理(NLP)" scheme="https://yuzhen-li.github.io/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-NLP/"/>
    
      <category term="textblog" scheme="https://yuzhen-li.github.io/tags/textblog/"/>
    
  </entry>
  
  <entry>
    <title>自然语言处理之spacy库</title>
    <link href="https://yuzhen-li.github.io/2018/04/15/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B9%8Bspacy%E5%BA%93/"/>
    <id>https://yuzhen-li.github.io/2018/04/15/自然语言处理之spacy库/</id>
    <published>2018-04-15T15:23:12.000Z</published>
    <updated>2018-04-15T16:07:36.741Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用-Python-spaCy-进行简易自然语言处理"><a href="#使用-Python-spaCy-进行简易自然语言处理" class="headerlink" title="使用 Python+spaCy 进行简易自然语言处理"></a>使用 Python+spaCy 进行简易自然语言处理</h1><h2 id="spaCy-简介及安装方法"><a href="#spaCy-简介及安装方法" class="headerlink" title="spaCy 简介及安装方法"></a>spaCy 简介及安装方法</h2><p>安装和编译 spaCy 比较方便，在ubuntu环境下，直接用pip安装即可：</p><pre><code>sudo apt-get install build-essential python-dev gitsudo pip install -U spacy</code></pre><p>不过安装完毕之后，需要下载相关的模型数据，以英文模型数据为例，可以用”all”参数下载所有的数据:</p><pre><code>sudo python -m spacy.en.download all</code></pre><p>可能提示 no module named spacy.en</p><p>则执行：python -m spacy download en 即可</p><p>现在可以快速测试一下spaCy的相关功能，我们以英文数据为例，spaCy目前主要支持英文和德文，对其他语言的支持正在陆续加入：</p><pre><code># 加载英文模型数据，稍许等待In [2]: nlp = spacy.load(&apos;en&apos;)</code></pre><h2 id="分词："><a href="#分词：" class="headerlink" title="分词："></a>分词：</h2><pre><code>In [3]: test_doc = nlp(u&quot;it&apos;s word tokenize test for spacy&quot;)In [4]: print(test_doc)it&apos;s word tokenize test for spacyIn [5]: for token in test_doc:print(token)...:it&apos;swordtokenizetestforspacy英文断句:In [6]: test_doc = nlp(u&apos;Natural language processing (NLP) deals with the application of computational models to text or speech data. Application areas within NLP include automatic (machine) translation between languages; dialogue systems, which allow a human to interact with a machine using natural language; and information extraction, where the goal is to transform unstructured text into structured (database) representations that can be searched and browsed in flexible ways. NLP technologies are having a dramatic impact on the way people interact with computers, on the way people interact with each other through the use of language, and on the way people access the vast amount of linguistic data now in electronic form. From a scientific viewpoint, NLP involves fundamental questions of how to structure formal models (for example statistical models) of natural language phenomena, and of how to design algorithms that implement these models.&apos;)In [7]: for sent in test_doc.sents:print(sent)...:Natural language processing (NLP) deals with the application of computational models to text or speech data.Application areas within NLP include automatic (machine) translation between languages; dialogue systems, which allow a human to interact with a machine using natural language; and information extraction, where the goal is to transform unstructured text into structured (database) representations that can be searched and browsed in flexible ways.NLP technologies are having a dramatic impact on the way people interact with computers, on the way people interact with each other through the use of language, and on the way people access the vast amount of linguistic data now in electronic form.From a scientific viewpoint, NLP involves fundamental questions of how to structure formal models (for example statistical models) of natural language phenomena, and of how to design algorithms that implement these models.</code></pre><h2 id="词性标注-POS-Tagging"><a href="#词性标注-POS-Tagging" class="headerlink" title="词性标注(POS Tagging):"></a>词性标注(POS Tagging):</h2><pre><code>In [10]: for token in test_doc:print(token, token.pos_, token.pos)....:(you, u&apos;PRON&apos;, 92)(are, u&apos;VERB&apos;, 97)(best, u&apos;ADJ&apos;, 82)(., u&apos;PUNCT&apos;, 94)(it, u&apos;PRON&apos;, 92)(is, u&apos;VERB&apos;, 97)(lemmatize, u&apos;ADJ&apos;, 82)(test, u&apos;NOUN&apos;, 89)(for, u&apos;ADP&apos;, 83)(spacy, u&apos;NOUN&apos;, 89)(., u&apos;PUNCT&apos;, 94)(I, u&apos;PRON&apos;, 92)(love, u&apos;VERB&apos;, 97)(these, u&apos;DET&apos;, 87)(books, u&apos;NOUN&apos;, 89)</code></pre><h2 id="命名实体识别（NER）："><a href="#命名实体识别（NER）：" class="headerlink" title="命名实体识别（NER）："></a>命名实体识别（NER）：</h2><pre><code>In [11]: test_doc = nlp(u&quot;Rami Eid is studying at Stony Brook University in New York&quot;)In [12]: for ent in test_doc.ents:print(ent, ent.label_, ent.label)....:(Rami Eid, u&apos;PERSON&apos;, 346)(Stony Brook University, u&apos;ORG&apos;, 349)(New York, u&apos;GPE&apos;, 350)</code></pre><p>代码统一整理：</p><pre><code>import spacynlp = spacy.load(&apos;en&apos;)test_doc = nlp(u&quot;it&apos;s word tokenize test for spacy&quot;)# 分词print(&quot;\n1、分词&quot;)print(test_doc)for token in test_doc:    print(token)# 分句print(&quot;\n2、分句&quot;)test_doc = nlp(u&apos;Natural language processing (NLP) deals with the application of computational models to text or speech data. Application areas within NLP include automatic (machine) translation between languages; dialogue systems, which allow a human to interact with a machine using natural language; and information extraction, where the goal is to transform unstructured text into structured (database) representations that can be searched and browsed in flexible ways. NLP technologies are having a dramatic impact on the way people interact with computers, on the way people interact with each other through the use of language, and on the way people access the vast amount of linguistic data now in electronic form. From a scientific viewpoint, NLP involves fundamental questions of how to structure formal models (for example statistical models) of natural language phenomena, and of how to design algorithms that implement these models.&apos;)print(test_doc)for sent in test_doc.sents:    print(sent)# 词干化print(&quot;\n3、词干化&quot;)test_doc = nlp(u&quot;you are best. it is lemmatize test for spacy. I love these books&quot;)print(test_doc)for token in test_doc:    print(token, token.lemma_, token.lemma)# 词性标注print(&quot;\n4、词性标注&quot;)print(test_doc)for token in test_doc:    print(token, token.pos_, token.pos)# 命名实体识别print(&quot;\n5、命名实体识别&quot;)test_doc = nlp(u&quot;Rami Eid is studying at Stony Brook University in New York&quot;)print(test_doc)for ent in test_doc.ents:    print(ent, ent.label_, ent.label)# 名词短语提取print(&quot;\n6、名词短语提取&quot;)test_doc = nlp(u&apos;Natural language processing (NLP) deals with the application of computational models to text or speech data. Application areas within NLP include automatic (machine) translation between languages; dialogue systems, which allow a human to interact with a machine using natural language; and information extraction, where the goal is to transform unstructured text into structured (database) representations that can be searched and browsed in flexible ways. NLP technologies are having a dramatic impact on the way people interact with computers, on the way people interact with each other through the use of language, and on the way people access the vast amount of linguistic data now in electronic form. From a scientific viewpoint, NLP involves fundamental questions of how to structure formal models (for example statistical models) of natural language phenomena, and of how to design algorithms that implement these models.&apos;)print(test_doc)for np in test_doc.noun_chunks:    print(np)# 基于词向量计算两个单词的相似度print(&quot;\n7、基于词向量计算两个单词的相似度&quot;)test_doc = nlp(u&quot;Apples and oranges are the same . Boots and hippos aren&apos;t.&quot;)print(test_doc)apples = test_doc[0]print(apples)oranges = test_doc[2]print(oranges)boots = test_doc[7]print(boots)hippos = test_doc[9]print(hippos)print(apples.similarity(oranges))print(boots.similarity(hippos))</code></pre><p>结果</p><pre><code>/usr/bin/python3.5 /home/wmmm/PycharmProjects/untitled/zstp.py1、分词it&apos;s word tokenize test for spacyit&apos;swordtokenizetestforspacy2、分句Natural language processing (NLP) deals with the application of computational models to text or speech data. Application areas within NLP include automatic (machine) translation between languages; dialogue systems, which allow a human to interact with a machine using natural language; and information extraction, where the goal is to transform unstructured text into structured (database) representations that can be searched and browsed in flexible ways. NLP technologies are having a dramatic impact on the way people interact with computers, on the way people interact with each other through the use of language, and on the way people access the vast amount of linguistic data now in electronic form. From a scientific viewpoint, NLP involves fundamental questions of how to structure formal models (for example statistical models) of natural language phenomena, and of how to design algorithms that implement these models.Natural language processing (NLP) deals with the application of computational models to text or speech data.Application areas within NLP include automatic (machine) translation between languages; dialogue systems, which allow a human to interact with a machine using natural language; and information extraction, where the goal is to transform unstructured text into structured (database) representations that can be searched and browsed in flexible ways.NLP technologies are having a dramatic impact on the way people interact with computers, on the way people interact with each other through the use of language, and on the way people access the vast amount of linguistic data now in electronic form.From a scientific viewpoint, NLP involves fundamental questions of how to structure formal models (for example statistical models) of natural language phenomena, and of how to design algorithms that implement these models.3、词干化you are best. it is lemmatize test for spacy. I love these booksyou -PRON- 561228191312463089are be 10382539506755952630best good 5711639017775284443. . 12646065887601541794it -PRON- 561228191312463089is be 10382539506755952630lemmatize lemmatize 4507259281035238268test test 1618900948208871284for for 16037325823156266367spacy spacy 10639093010105930009. . 12646065887601541794I -PRON- 561228191312463089love love 3702023516439754181these these 6459564349623679250books book 138144331071114592974、词性标注you are best. it is lemmatize test for spacy. I love these booksyou PRON 94are VERB 99best ADJ 83. PUNCT 96it PRON 94is VERB 99lemmatize ADJ 83test NOUN 91for ADP 84spacy NOUN 91. PUNCT 96I PRON 94love VERB 99these DET 89books NOUN 915、命名实体识别Rami Eid is studying at Stony Brook University in New YorkRami Eid PERSON 378Stony Brook University ORG 381New York GPE 3826、名词短语提取Natural language processing (NLP) deals with the application of computational models to text or speech data. Application areas within NLP include automatic (machine) translation between languages; dialogue systems, which allow a human to interact with a machine using natural language; and information extraction, where the goal is to transform unstructured text into structured (database) representations that can be searched and browsed in flexible ways. NLP technologies are having a dramatic impact on the way people interact with computers, on the way people interact with each other through the use of language, and on the way people access the vast amount of linguistic data now in electronic form. From a scientific viewpoint, NLP involves fundamental questions of how to structure formal models (for example statistical models) of natural language phenomena, and of how to design algorithms that implement these models.Natural language processingthe applicationcomputational modelsApplication areasNLPautomatic (machine) translationlanguagesdialogue systemsa humana machinenatural languageinformation extractionthe goalunstructured textstructured (database) representationsflexible waysNLP technologiesa dramatic impactthe waypeoplecomputersthe waypeoplethe uselanguagethe waypeoplethe vast amountlinguistic dataelectronic forma scientific viewpointNLPfundamental questionsformal modelsexamplenatural language phenomenaalgorithmsthese models7、基于词向量计算两个单词的相似度Apples and oranges are the same . Boots and hippos aren&apos;t.ApplesorangesBootshippos0.5180960.158362进程已结束,退出代码0</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;使用-Python-spaCy-进行简易自然语言处理&quot;&gt;&lt;a href=&quot;#使用-Python-spaCy-进行简易自然语言处理&quot; class=&quot;headerlink&quot; title=&quot;使用 Python+spaCy 进行简易自然语言处理&quot;&gt;&lt;/a&gt;使用 Pytho
      
    
    </summary>
    
      <category term="技术博客" scheme="https://yuzhen-li.github.io/categories/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="自然语言处理(NLP)" scheme="https://yuzhen-li.github.io/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-NLP/"/>
    
      <category term="spacy" scheme="https://yuzhen-li.github.io/tags/spacy/"/>
    
  </entry>
  
  <entry>
    <title>自然语言（分词、分词、实体识别等）集成投票算法实例</title>
    <link href="https://yuzhen-li.github.io/2018/04/15/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%EF%BC%88%E5%88%86%E8%AF%8D%E3%80%81%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8%E3%80%81%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E7%AD%89%EF%BC%89%E9%9B%86%E6%88%90%E6%8A%95%E7%A5%A8%E7%AE%97%E6%B3%95%E5%AE%9E%E4%BE%8B/"/>
    <id>https://yuzhen-li.github.io/2018/04/15/自然语言（分词、词性标注、实体识别等）集成投票算法实例/</id>
    <published>2018-04-15T15:23:12.000Z</published>
    <updated>2018-04-16T07:32:42.738Z</updated>
    
    <content type="html"><![CDATA[<h1 id="源代码注释"><a href="#源代码注释" class="headerlink" title="源代码注释"></a>源代码注释</h1><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">#获取数字编号</span><br><span class="line">def numCode(s1_str):</span><br><span class="line">    #s1_str = <span class="string">'|'</span>.<span class="keyword">join</span>(s_str)</span><br><span class="line">    tempNum = <span class="number">1</span></span><br><span class="line">    saveNum = []</span><br><span class="line">    <span class="keyword">for</span> s1_s in s1_str:</span><br><span class="line">        <span class="keyword">if</span> s1_s != <span class="string">'/'</span>:</span><br><span class="line">            saveNum.<span class="keyword">append</span>(tempNum)</span><br><span class="line">        tempNum = tempNum + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> saveNum</span><br><span class="line">#三种分词方法进行融合</span><br><span class="line">def decisonThree(s,s1,s2,s3):</span><br><span class="line">    # s = [<span class="string">'我'</span>, <span class="string">'是'</span>, <span class="string">'招'</span>, <span class="string">'商'</span>, <span class="string">'银'</span>, <span class="string">'行'</span>, <span class="string">'的'</span>, <span class="string">'一'</span>, <span class="string">'员'</span>, <span class="string">'。'</span>]</span><br><span class="line">    # s1 = [<span class="string">'我'</span>, <span class="string">'是'</span>, <span class="string">'招商'</span>, <span class="string">'银行的'</span>, <span class="string">'一员。'</span>]</span><br><span class="line">    # s2 = [<span class="string">'我是'</span>, <span class="string">'招商'</span>, <span class="string">'银行'</span>, <span class="string">'的'</span>, <span class="string">'一员'</span>, <span class="string">'。'</span>]</span><br><span class="line">    # s3 = [<span class="string">'我'</span>, <span class="string">'是招'</span>, <span class="string">'商'</span>, <span class="string">'银行'</span>, <span class="string">'的'</span>, <span class="string">'一员'</span>, <span class="string">'。'</span>]</span><br><span class="line">    a1 = numCode(s1) #我爱你/，/桂/书品/！</span><br><span class="line">    b1 = numCode(s2) </span><br><span class="line">    c1 = numCode(s3)</span><br><span class="line">    <span class="keyword">print</span>(s)</span><br><span class="line">    <span class="keyword">print</span>(s1)#我爱你/，/桂/书品/！</span><br><span class="line">    <span class="keyword">print</span>(a1)#[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">12</span>]  遇到/，序号+<span class="number">1</span>，不添加到列表中</span><br><span class="line">    <span class="keyword">print</span>(s2)#我/爱/你/，/桂/书品/！</span><br><span class="line">    <span class="keyword">print</span>(b1)#[<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">14</span>]</span><br><span class="line">    <span class="keyword">print</span>(s3)#我/爱/你/，/桂/书品/！</span><br><span class="line">    <span class="keyword">print</span>(c1)#[<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">14</span>]</span><br><span class="line">    d1 = []</span><br><span class="line">    <span class="keyword">for</span> i in <span class="built_in">range</span>(<span class="built_in">len</span>(a1)):</span><br><span class="line">        <span class="keyword">if</span> ((a1[i] == b1[i]) <span class="built_in">and</span> (a1[i] == c1[i])):</span><br><span class="line">            d1.<span class="keyword">append</span>(a1[i])</span><br><span class="line">            # <span class="keyword">continue</span></span><br><span class="line">        elif a1[i] == b1[i]:</span><br><span class="line">            d1.<span class="keyword">append</span>(a1[i])</span><br><span class="line">            <span class="keyword">for</span> ii in <span class="built_in">range</span>((i + <span class="number">1</span>), <span class="built_in">len</span>(c1)):</span><br><span class="line">                <span class="keyword">if</span> a1[i] &lt; c1[i]:</span><br><span class="line">                    c1[ii] = c1[ii] - <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    c1[ii] = c1[ii] + <span class="number">1</span></span><br><span class="line">        elif a1[i] == c1[i]:   ##投票算法的核心思想是如果其中两种的分词结果一样，则分词结果为票数多的分词结果。</span><br><span class="line">            d1.<span class="keyword">append</span>(a1[i])</span><br><span class="line">            <span class="keyword">for</span> ii in <span class="built_in">range</span>((i + <span class="number">1</span>), <span class="built_in">len</span>(b1)):</span><br><span class="line">                <span class="keyword">if</span> a1[i] &lt; b1[i]:</span><br><span class="line">                    b1[ii] = b1[ii] - <span class="number">1</span>###使不同的分词+<span class="number">1</span>或者-<span class="number">1</span>，从下一个位置开始比较。</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    b1[ii] = b1[ii] + <span class="number">1</span></span><br><span class="line">        elif c1[i] == b1[i]:</span><br><span class="line">            d1.<span class="keyword">append</span>(b1[i])</span><br><span class="line">            <span class="keyword">for</span> ii in <span class="built_in">range</span>((i + <span class="number">1</span>), <span class="built_in">len</span>(a1)):</span><br><span class="line">                <span class="keyword">if</span> b1[i] &lt; a1[i]:</span><br><span class="line">                    a1[ii] = a1[ii] - <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    a1[ii] = a1[ii] + <span class="number">1</span></span><br><span class="line">    <span class="keyword">print</span>(<span class="string">'Decision Fusion:'</span>)</span><br><span class="line">    <span class="keyword">print</span>(d1)#[<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">14</span>]</span><br><span class="line">    sumPos = <span class="number">0</span></span><br><span class="line">    listTemp = []</span><br><span class="line">    <span class="keyword">for</span> i in <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">max</span>(d1)):</span><br><span class="line">        listTemp.<span class="keyword">append</span>(<span class="string">'|'</span>)</span><br><span class="line">    sNum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">print</span>(listTemp)#[<span class="string">'|'</span>, <span class="string">'|'</span>, <span class="string">'|'</span>, <span class="string">'|'</span>, <span class="string">'|'</span>, <span class="string">'|'</span>, <span class="string">'|'</span>, <span class="string">'|'</span>, <span class="string">'|'</span>, <span class="string">'|'</span>, <span class="string">'|'</span>, <span class="string">'|'</span>, <span class="string">'|'</span>, <span class="string">'|'</span>]，形成d1中数量最大的个数的<span class="string">'|'</span></span><br><span class="line">    <span class="keyword">for</span> nPos in d1:</span><br><span class="line">        listTemp[nPos - <span class="number">1</span>] = s[sNum]</span><br><span class="line">        sNum = sNum + <span class="number">1</span></span><br><span class="line">    <span class="keyword">print</span>(listTemp)#[<span class="string">'我'</span>, <span class="string">'|'</span>, <span class="string">'爱'</span>, <span class="string">'|'</span>, <span class="string">'你'</span>, <span class="string">'|'</span>, <span class="string">'，'</span>, <span class="string">'|'</span>, <span class="string">'桂'</span>, <span class="string">'|'</span>, <span class="string">'书'</span>, <span class="string">'品'</span>, <span class="string">'|'</span>, <span class="string">'！'</span>]把listTemp中<span class="string">'|'</span>通过d1的序号提换成s中的字符。</span><br><span class="line">    outputStr = <span class="string">''</span>.<span class="keyword">join</span>(listTemp)</span><br><span class="line">    outputStr = outputStr.<span class="keyword">split</span>(<span class="string">'|'</span>)</span><br><span class="line">    <span class="keyword">print</span>(outputStr)#[<span class="string">'我'</span>, <span class="string">'爱'</span>, <span class="string">'你'</span>, <span class="string">'，'</span>, <span class="string">'桂'</span>, <span class="string">'书品'</span>, <span class="string">'！'</span>]</span><br><span class="line">    <span class="keyword">return</span> outputStr</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;源代码注释&quot;&gt;&lt;a href=&quot;#源代码注释&quot; class=&quot;headerlink&quot; title=&quot;源代码注释&quot;&gt;&lt;/a&gt;源代码注释&lt;/h1&gt;&lt;figure class=&quot;highlight vim&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="技术博客" scheme="https://yuzhen-li.github.io/categories/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="自然语言处理(NLP)" scheme="https://yuzhen-li.github.io/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-NLP/"/>
    
      <category term="分词" scheme="https://yuzhen-li.github.io/tags/%E5%88%86%E8%AF%8D/"/>
    
      <category term="投票集成算法" scheme="https://yuzhen-li.github.io/tags/%E6%8A%95%E7%A5%A8%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>诗和远方1</title>
    <link href="https://yuzhen-li.github.io/2018/04/15/%E8%AF%97%E5%92%8C%E8%BF%9C%E6%96%B91/"/>
    <id>https://yuzhen-li.github.io/2018/04/15/诗和远方1/</id>
    <published>2018-04-15T13:31:50.000Z</published>
    <updated>2018-04-15T13:32:35.383Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="散文随笔" scheme="https://yuzhen-li.github.io/categories/%E6%95%A3%E6%96%87%E9%9A%8F%E7%AC%94/"/>
    
    
  </entry>
  
  <entry>
    <title>诗和远方</title>
    <link href="https://yuzhen-li.github.io/2018/04/15/%E8%AF%97%E5%92%8C%E8%BF%9C%E6%96%B9/"/>
    <id>https://yuzhen-li.github.io/2018/04/15/诗和远方/</id>
    <published>2018-04-15T13:17:33.000Z</published>
    <updated>2018-04-15T13:18:11.006Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="散文随笔" scheme="https://yuzhen-li.github.io/categories/%E6%95%A3%E6%96%87%E9%9A%8F%E7%AC%94/"/>
    
    
  </entry>
  
  <entry>
    <title>Stanford_CoreNLP在Ubuntu下的安装与使用</title>
    <link href="https://yuzhen-li.github.io/2018/04/15/Stanford-CoreNLP%E5%9C%A8Ubuntu%E4%B8%8B%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    <id>https://yuzhen-li.github.io/2018/04/15/Stanford-CoreNLP在Ubuntu下的安装与使用/</id>
    <published>2018-04-15T12:22:48.000Z</published>
    <updated>2018-04-15T15:54:27.105Z</updated>
    
    <content type="html"><![CDATA[<h1 id="stanford-CoreNLP安装以及使用"><a href="#stanford-CoreNLP安装以及使用" class="headerlink" title="stanford CoreNLP安装以及使用"></a>stanford CoreNLP安装以及使用</h1><p>stanford CoreNLP快搞死我了，查了不少资料花费了接近3个小时，才安装完成，并且学会使用。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Stanford CoreNLP提供了一系列自然语言分析工具。它能够给出基本的词形，词性，不管是公司名还是人名等，格式化的日期，时间，量词，并且能够标记句子的结构，语法形式和字词依赖，指明那些名字指向同样的实体，指明情绪，提取发言中的开放关系等。如果需要进行如下任务，Standfrod CoreNLP正合适：</p><pre><code>1一个集成的语言分析工具集；2进行快速，可靠的任意文本分析；3.整体的高质量的文本分析;4.支持多种主流语言;5.多种编程语言的易用接口;6.方便的简单的部署web服务。</code></pre><p>Stanford CoreNLP是一个集成的框架。框架的目标是使得应用一大堆语言分析工具分析大量的文本变得简单。COreNLP工具可以仅仅通过两行命令执行大量的文本分析工作。框架设计的初衷就是高度灵活的可扩展性的。通过一个单独的名利ing就可以选择某个工具的开启和关闭。Stanford CoreNLP集成了许多斯坦福的NLP工具，包括：词性标记（POS），命名实体识别（NER），语法，参数分析系统，情绪分析，自举模式学习，和开放信息提取工具。这个框架的分析为高等级和指定领域的文本理解应用程序提供了基本的构件。</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>首先需要安装Java运行环境，以Ubuntu 12.04为例，安装Java运行环境仅需要两步：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get <span class="keyword">install</span> <span class="keyword">default</span>-jre</span><br><span class="line">sudo apt-<span class="keyword">get</span> <span class="keyword">install</span> <span class="keyword">default</span>-jdk</span><br></pre></td></tr></table></figure></p><p>然后下载Stanford coreNLP 包：<br><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget http://nlp.stanford.edu/software/stanford-corenlp-full<span class="string">-2018</span><span class="string">-02</span><span class="string">-27</span>.zip</span><br><span class="line"></span><br><span class="line">unzip stanford-corenlp-full<span class="string">-2018</span><span class="string">-02</span><span class="string">-27</span>.zip</span><br><span class="line"></span><br><span class="line">cd stanford-corenlp-full<span class="string">-2018</span><span class="string">-02</span><span class="string">-27</span>/</span><br></pre></td></tr></table></figure></p><p>配置环境变量：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> `<span class="builtin-name">find</span> . -name <span class="string">"*.jar"</span>`; <span class="keyword">do</span> <span class="builtin-name">export</span> <span class="attribute">CLASSPATH</span>=<span class="string">"<span class="variable">$CLASSPATH</span>:`realpath <span class="variable">$file</span>`"</span>; done</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> `<span class="builtin-name">find</span> /path/<span class="keyword">to</span>/corenlp/ -name <span class="string">"*.jar"</span>`; <span class="keyword">do</span> <span class="builtin-name">export</span> <span class="attribute">CLASSPATH</span>=<span class="string">"<span class="variable">$CLASSPATH</span>:`realpath <span class="variable">$file</span>`"</span>; done</span><br></pre></td></tr></table></figure><p>安装：<br><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip3 <span class="keyword">install</span> stanfordcorenlp</span><br></pre></td></tr></table></figure></p><p>处理中文还需要下载中文的模型jar文件，然后放到stanford-corenlp-full-2018-02-27根目录下即可<br><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://nlp.stanford.edu/software/stanford-chinese-corenlp<span class="string">-2018</span><span class="string">-02</span><span class="string">-27</span>-models.jar</span><br></pre></td></tr></table></figure></p><h2 id="中文使用方法"><a href="#中文使用方法" class="headerlink" title="中文使用方法"></a>中文使用方法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> stanfordcorenlp <span class="keyword">import</span> StanfordCoreNLP</span><br><span class="line"></span><br><span class="line">nlp = StanfordCoreNLP(<span class="string">r'/mnt/f/CMBNLP/stanford-corenlp-full-2018-02-27/'</span>, lang=<span class="string">'zh'</span>) <span class="comment">## 这里是coreNLP的路径</span></span><br><span class="line"></span><br><span class="line">sentence = <span class="string">'清华大学位于北京。'</span></span><br><span class="line"><span class="keyword">print</span> nlp.word_tokenize(sentence)</span><br><span class="line"><span class="keyword">print</span> nlp.pos_tag(sentence)</span><br><span class="line"><span class="keyword">print</span> nlp.ner(sentence)</span><br><span class="line"><span class="keyword">print</span> nlp.parse(sentence)</span><br><span class="line"><span class="keyword">print</span> nlp.dependency_parse(sentence)</span><br></pre></td></tr></table></figure><h2 id="英文使用方法"><a href="#英文使用方法" class="headerlink" title="英文使用方法"></a>英文使用方法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> stanfordcorenlp <span class="keyword">import</span> StanfordCoreNLP</span><br><span class="line"></span><br><span class="line">nlp = StanfordCoreNLP(<span class="string">r'/mnt/f/CMBNLP/stanford-corenlp-full-2018-02-27/'</span>) <span class="comment">## 这里是coreNLP的路径,与中文相比，省略了, lang='zh'</span></span><br><span class="line"></span><br><span class="line">sentence = <span class="string">'You are a beautiful girl1'</span></span><br><span class="line"><span class="keyword">print</span> nlp.word_tokenize(sentence)</span><br><span class="line"><span class="keyword">print</span> nlp.pos_tag(sentence)</span><br><span class="line"><span class="keyword">print</span> nlp.ner(sentence)</span><br><span class="line"><span class="keyword">print</span> nlp.parse(sentence)</span><br><span class="line"><span class="keyword">print</span> nlp.dependency_parse(sentence)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;stanford-CoreNLP安装以及使用&quot;&gt;&lt;a href=&quot;#stanford-CoreNLP安装以及使用&quot; class=&quot;headerlink&quot; title=&quot;stanford CoreNLP安装以及使用&quot;&gt;&lt;/a&gt;stanford CoreNLP安装以及
      
    
    </summary>
    
      <category term="技术博客" scheme="https://yuzhen-li.github.io/categories/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="NLP" scheme="https://yuzhen-li.github.io/tags/NLP/"/>
    
      <category term="stanford" scheme="https://yuzhen-li.github.io/tags/stanford/"/>
    
      <category term="CoreNLP" scheme="https://yuzhen-li.github.io/tags/CoreNLP/"/>
    
  </entry>
  
</feed>
